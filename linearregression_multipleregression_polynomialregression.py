# -*- coding: utf-8 -*-
"""LinearRegression_MultipleRegression_PolynomialRegression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zjVbs_XIbdWDmVVMyO6VAn2G4U1Cu7jv

# **Linear Regression**

https://realpython.com/linear-regression-in-python/ </br>
https://www.sfu.ca/~mjbrydon/tutorials/BAinPy/09_regression.html </br>
https://www.xlstat.com/en/solutions/features/linear-regression </br>
https://www.datacamp.com/tutorial/simple-linear-regression </br>
https://www.w3schools.com/python/python_ml_multiple_regression.asp </br>
https://www.w3schools.com/python/python_ml_polynomial_regression.asp

# **Simple linear regression** *helps make predictions and understand relationships between one independent variable and one dependent variable. For example, you might want to know how a treeâ€™s height (independent variable) affects the number of leaves it has (dependent variable). By collecting data and fitting a simple linear regression model, you could predict the number of leaves based on the tree's height.*

Note: A distinction is usually made between simple regression(with only one explanatory variable) and multiple regression (several explanatory variables) although the overall concept and calculation methods are identical.
"""

#Import libraries

import statsmodels.api as sm
import pandas as pd

con = pd.read_csv('concrete_data.csv')
con.head()

Y = con['Strength']
X = con['Fly Ash']
X.head()

#Adding a column for the constant

X = sm.add_constant(X)
X.head(3)

#Running the Model

model = sm.OLS(Y, X, missing='drop')
model_result = model.fit()
model_result.summary()

"""### *Multiple Linear Regression With scikit-learn*

*Multiple regression is like linear regression, but with more than one independent value, meaning that we try to predict a value based on two or more variables.*
"""

car = pd.read_csv('car_data.csv')
car.head(3)

X_car = car[['Weight', 'Volume']]
y_car = car['CO2']

#Import Library

from sklearn import linear_model

regr = linear_model.LinearRegression()
regr.fit(X_car, y_car)

predictedCO2 = regr.predict([[3300, 1300]])
print(predictedCO2)

#Get results

car_r_sq = regr.score(X_car, y_car)
car_intercept, car_coefficients = regr.intercept_, regr.coef_

print(f"coefficient of determination: {car_r_sq}")

print(f"intercept: {car_intercept}")

print(f"intercept: {car_coefficients}")

"""# *Polynomial Regression With scikit-learn*

*Polynomial regression, like linear regression, uses the relationship between the variables x and y to find the best way to draw a line through the data points.*
"""

#Import relevant libraries

import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures

#Provide data

poly_X = [
   [0, 1], [5, 1], [15, 2], [25, 5], [35, 11], [45, 15], [55, 34], [60, 35]
 ]
poly_y = [4, 5, 20, 14, 32, 22, 38, 43]

poly_x, poly_y = np.array(poly_X), np.array(poly_y)

#Transform input data

poly_x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(poly_x)

#Create a model and fit it

poly_model = LinearRegression().fit(poly_x_, poly_y)

#Get results

r_sq = poly_model.score(poly_x_, poly_y)
intercept_, coefficients_ = poly_model.intercept_, poly_model.coef_

#Predict response

y_pred = poly_model.predict(poly_x_)

print(f"coefficient of determination: {r_sq}")

print(f"intercept: {intercept}")

print(f"intercept: {coefficients}")

print(f"intercept: {y_pred}")